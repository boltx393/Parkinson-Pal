{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this project we are going to predict if a patient is suffering from Parkinson's disease based on the audio/ voice measures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('parkinsons.data')\n",
    "# Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "# The dataset has 195 rows and 24 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "# There are no null values in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "# Using df.info we can find the presence of missing values at the same time view the types of columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "# The describe() method is used for calculating some statistical data like percentile, mean and std of the numerical values of the Series or DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "# Displaying the column names of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the column names as seen in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute Information:\n",
    "\n",
    "## Matrix column entries (attributes):\n",
    "### name - ASCII subject name and recording number\n",
    "MDVP:Fo(Hz) - Average vocal fundamental frequency\n",
    "MDVP:Fhi(Hz) - Maximum vocal fundamental frequency\n",
    "MDVP:Flo(Hz) - Minimum vocal fundamental frequency\n",
    "MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several \n",
    "measures of variation in fundamental frequency\n",
    "MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude\n",
    "NHR,HNR - Two measures of ratio of noise to tonal components in the voice\n",
    "status - Health status of the subject (one) - Parkinson's, (zero) - healthy\n",
    "RPDE,D2 - Two nonlinear dynamical complexity measures\n",
    "DFA - Signal fractal scaling exponent\n",
    "spread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'] \n",
    "# The Status column is the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# status - Health status of the subject (one) - Parkinson's, (zero) - healthy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "df.status.hist()\n",
    "plt.xlabel('status')\n",
    "plt.ylabel('Frequencies')\n",
    "plt.plot()\n",
    "# The dataset has high number of patients effected with Parkinson's disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"status\",y=\"NHR\",data=df);\n",
    "# The patients effected with Parkinson's disease have high NHR that is the measures of ratio of noise to tonal components in the voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"status\",y=\"HNR\",data=df);\n",
    "# The patients effected with Parkinson's disease have high HNR that is the measures of ratio of noise to tonal components in the voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"status\",y=\"RPDE\",data=df);\n",
    "# The nonlinear dynamical complexity measure RPDE is high in the patients effected with Parkinson's disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=3\n",
    "cols=7\n",
    "fig, ax=plt.subplots(nrows=rows,ncols=cols,figsize=(16,4))\n",
    "col=df.columns\n",
    "index=1\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        sns.distplot(df[col[index]],ax=ax[i][j])\n",
    "        index=index+1\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A distribution plot displays a distribution and range of a set of numeric values plotted against a dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['name'],axis=1,inplace=True)\n",
    "# Removing  name column for machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(labels=['status'],axis=1)\n",
    "Y=df['status']\n",
    "X.head()\n",
    "### Spitting the dataset into x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()\n",
    "# Displaying X head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()\n",
    "# Displaying Y head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=40)\n",
    "print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)\n",
    "# Splitting the data into x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression().fit(X_train, Y_train)\n",
    "\n",
    "#predict on train \n",
    "train_preds = log_reg.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds))\n",
    "\n",
    "#predict on test\n",
    "test_preds = log_reg.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds))\n",
    "print('-'*50)\n",
    "\n",
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is: \", confusion_matrix(Y_train, train_preds))\n",
    "print(\"confusion_matrix test is: \", confusion_matrix(Y_test, test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF=RandomForestClassifier().fit(X_train,Y_train)\n",
    "#predict on train \n",
    "train_preds2 = RF.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds2))\n",
    "\n",
    "#predict on test\n",
    "test_preds2 = RF.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds2))\n",
    "\n",
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is: \", confusion_matrix(Y_train, train_preds2))\n",
    "print(\"confusion_matrix test is: \", confusion_matrix(Y_test, test_preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds2).sum(),'/',((Y_test == test_preds2).sum()+(Y_test != test_preds2).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let us go ahead and compare the predicted and actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds2,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the actual and predicted values to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf=pd.DataFrame(data=[test_preds2,Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above 0 means Predicted Value and 1 is True Value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest model performs better compared to other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest model gives us an accuracy of 94 percent compared to logistic regression which gave us 84 percent accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying other machine learning models to see if there is improvement in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model on train data \n",
    "DT = DecisionTreeClassifier().fit(X,Y)\n",
    "\n",
    "#predict on train \n",
    "train_preds3 = DT.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds3))\n",
    "\n",
    "#predict on test\n",
    "test_preds3 = DT.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is: \", confusion_matrix(Y_train, train_preds3))\n",
    "print(\"confusion_matrix test is: \", confusion_matrix(Y_test, test_preds3))\n",
    "print('Wrong predictions out of total')\n",
    "print('-'*50)\n",
    "\n",
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds3).sum(),'/',((Y_test == test_preds3).sum()+(Y_test != test_preds3).sum()))\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB=GaussianNB()\n",
    "NB.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model on train data \n",
    "NB=GaussianNB()\n",
    "NB.fit(X_train,Y_train)\n",
    "\n",
    "#predict on train \n",
    "train_preds4 = NB.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds4))\n",
    "\n",
    "#predict on test\n",
    "test_preds4 = NB.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is: \", confusion_matrix(Y_train, train_preds4))\n",
    "print(\"confusion_matrix test is: \", confusion_matrix(Y_test, test_preds4))\n",
    "print('Wrong predictions out of total')\n",
    "print('-'*50)\n",
    "\n",
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds4).sum(),'/',((Y_test == test_preds4).sum()+(Y_test != test_preds4).sum()))\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-NearestNeighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model on train data \n",
    "KNN = KNeighborsClassifier().fit(X_train,Y_train)\n",
    "#predict on train \n",
    "train_preds5 = KNN.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds5))\n",
    "\n",
    "#predict on test\n",
    "test_preds5 = KNN.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is: \", confusion_matrix(Y_train, train_preds5))\n",
    "print(\"confusion_matrix test is: \", confusion_matrix(Y_test, test_preds5))\n",
    "print('Wrong predictions out of total')\n",
    "print('-'*50)\n",
    "\n",
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds5).sum(),'/',((Y_test == test_preds5).sum()+(Y_test != test_preds5).sum()))\n",
    "\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SupportVectorMachine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model on train data \n",
    "SVM = SVC(kernel='linear')\n",
    "SVM.fit(X_train, Y_train)\n",
    "\n",
    "#predict on train \n",
    "train_preds6 = SVM.predict(X_train)\n",
    "#accuracy on train\n",
    "print(\"Model accuracy on train is: \", accuracy_score(Y_train, train_preds6))\n",
    "\n",
    "#predict on test\n",
    "test_preds6 = SVM.predict(X_test)\n",
    "#accuracy on test\n",
    "print(\"Model accuracy on test is: \", accuracy_score(Y_test, test_preds6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "print(\"confusion_matrix train is: \", confusion_matrix(Y_train, train_preds6))\n",
    "print(\"confusion_matrix test is: \", confusion_matrix(Y_test, test_preds6))\n",
    "print('Wrong predictions out of total')\n",
    "print('-'*50)\n",
    "\n",
    "print(\"recall\", metrics.recall_score(Y_test, test_preds6))\n",
    "print('-'*50)\n",
    "\n",
    "# Wrong Predictions made.\n",
    "print((Y_test !=test_preds6).sum(),'/',((Y_test == test_preds6).sum()+(Y_test != test_preds6).sum()))\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kappa Score\n",
    "print('KappaScore is: ', metrics.cohen_kappa_score(Y_test,test_preds6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
